<?xml version='1.0' encoding='utf-8' standalone='yes'?>
<?xml-stylesheet href="./_c74_ref.xsl" type="text/xsl"?>
<!--
Part of the Fluid Corpus Manipulation Project (http://www.flucoma.org/)
Copyright 2017-2019 University of Huddersfield.
Licensed under the BSD-3 License.
See license.md file in the project root for full license information.
This project has received funding from the European Research Council (ERC)
under the European Unionâ€™s Horizon 2020 research and innovation programme
(grant agreement No 725899).
-->
<!-- DO NOT EDIT THIS FILE ... YOU WILL LOSE YOUR WORK -->
<c74object name='fluid.mlpregressor~' category='FluidCorpusManuipulation'>
	<digest>Regression with a multi-layer perceptron</digest>
	<description><div class="document">
<p>Perform regression between :fluid-obj:<a href="#id1"><span class="problematic" id="id2">`</span></a>DataSet`s using a Multi-Layer Perception neural network.</p>
<div class="system-message" id="id1">
<p class="system-message-title">System Message: WARNING/2 (<tt class="docutils">&lt;string&gt;</tt>, line 1); <em><a href="#id2">backlink</a></em></p>
Inline interpreted text or phrase reference start-string without end-string.</div>
</div>
</description>
  <discussion>
      <h4><openfilelink filename="Fluid Corpus Manipulation Toolkit.maxpat">Open the Overview Patch</openfilelink></h4>
    

		fluid.mlpregressor~ is part of the Fluid Decomposition Toolkit of the FluCoMa project. For more explanations, learning material, and discussions on its musicianly uses, visit <a href="http://www.flucoma.org/">flucoma.org</a>.

  </discussion>
	<!--METADATA-->
	<metadatalist>
		<metadata name='author'>FluCoMa</metadata>
		<metadata name='tag'>Fluid Decomposition</metadata>
		<metadata name='tag'>corpus</metadata>
	</metadatalist>
	<!--ARGUMENTS-->
	<objarglist><objarg name='name' optional='1' type='number'>
        <digest>
          Name
        </digest>
        <description>
          
          
        </description><attributelist>
          <attribute name="default" get="1" set="1" type="int" size='1' value='' />
        </attributelist></objarg><!-- <objarg name='function' optional='1' type='number'>
			<digest>Initial easing function to use</digest>
			<description>Initial easing function to use. </description>
		</objarg>-->
	</objarglist>
	<!--MESSAGES-->
  <methodlist><method name="reset">
      <arglist />
      <digest>
        Return the object to its original state
      </digest>
      <description>
        Calling <m>reset</m> will change parameter values back to those the object was <i>created</i> with, i.e. any attribute values set in the box will be retained
      </description>
    </method>
    <method name='fit'>
			<arglist><arg name= "sourceDataSet" optional='0' type="symbol" /><arg name= "targetDataSet" optional='0' type="symbol" /></arglist>
			<description>
        <div class="document">
<p>Train the network to map between a source and target <o>fluid.dataset~</o></p>
</div>

        <h5>Argument details:</h5>
        <ul><li>sourceDataSet: <div class="document">
<p>Source data</p>
</div>
</li><li>targetDataSet: <div class="document">
<p>Target data</p>
</div>
</li></ul>
			</description>
		</method>
    
    <method name='predict'>
			<arglist><arg name= "sourceDataSet" optional='0' type="symbol" /><arg name= "targetDataSet" optional='0' type="symbol" /></arglist>
			<description>
        <div class="document">
<p>Apply the learned mapping to a <o>fluid.dataset~</o> (given a trained network)</p>
</div>

        <h5>Argument details:</h5>
        <ul><li>sourceDataSet: <div class="document">
<p>Input data</p>
</div>
</li><li>targetDataSet: <div class="document">
<p>Output data</p>
</div>
</li></ul>
			</description>
		</method>
    
    <method name='predictpoint'>
			<arglist><arg name= "sourceBuffer" optional='0' type="symbol" /><arg name= "targetBuffer" optional='0' type="symbol" /></arglist>
			<description>
        <div class="document">
<p>Apply the learned mapping to a single data point in a buffer~</p>
</div>

        <h5>Argument details:</h5>
        <ul><li>sourceBuffer: <div class="document">
<p>Input point</p>
</div>
</li><li>targetBuffer: <div class="document">
<p>Output point</p>
</div>
</li></ul>
			</description>
		</method>
    
    <method name='clear'>
			<arglist></arglist>
			<description>
        <div class="document">
<p>This will erase all the learning done in the neural network.</p>
</div>

        
        <ul></ul>
			</description>
		</method>
    
    <method name='cols'>
			<arglist></arglist>
			<description>
        <div class="document">
<p>The number of columns (dimensions) in this model or dataset / labeset</p>
</div>

        
        <ul></ul>
			</description>
		</method>
    
    <method name='size'>
			<arglist></arglist>
			<description>
        <div class="document">
<p>The number of data points (entries / observations) in this model or dataset / labeset</p>
</div>

        
        <ul></ul>
			</description>
		</method>
    
     <method name='load'>
       <arglist>
         <arg name="dictionary" optional='0' type='dictionary'/>
       </arglist>
       <description>Replace the internal state of the object from a <o>dict</o>. The message should take the form <code>load dictionary &lt;dictid&gt;</code>
      </description>
     </method>
     
     <method name='dump'>
       <digest>Dump the state of this object from the dump outlet as a <o>dict</o>.</digest>
     </method>
     
     <method name='write'>
       <arglist>
         <arg name="path" optional="1" type='symbol, optional'/>
       </arglist>
       <description>Save the internal state of the object to a JSON file on disk. With no argument, a file dialog will appear to choose the file.
      </description>
     </method>
    
     <method name='read'>
       <arglist>
         <arg name="path" optional="1" type='symbol, optional'/>
       </arglist>
       <description>Replace the internal state of the object from a JSON file on disk. With no argument, a file dialog will appear to choose the file.
      </description>
     </method>
     </methodlist>
	<!--ATTRIBUTES-->
	<attributelist><attribute name='activation' get='1' set='1' type='int' size='1'>
        <digest>
          Activation Function
        </digest>
        <description>
          <div class="document">
<p>The activation function to use for the hidden layer units. Beware of the permitted ranges of each: relu (0-&gt;inf), sigmoid (0-&gt;1), tanh (-1,1)</p>
</div>

          
        </description><attributelist><attribute name="default" get="1" set="1" type="int" size='1' value='2' /></attributelist></attribute><attribute name='batchsize' get='1' set='1' type='int' size='1'>
        <digest>
          Batch Size
        </digest>
        <description>
          <div class="document">
<p>The training batch size.</p>
</div>

          <h5>Constraints</h5><ul><li>Minimum: 1</li></ul>
        </description><attributelist><attribute name="default" get="1" set="1" type="int" size='1' value='50' /></attributelist></attribute><attribute name='hidden' get='1' set='1' type='int' size='1'>
        <digest>
          Hidden Layer Sizes
        </digest>
        <description>
          <div class="document">
<p>An <cite>Classes/Array</cite> that gives the sizes of any hidden layers in the network (default is two hidden layers of three units each).</p>
</div>

          
        </description><attributelist><attribute name="default" get="1" set="1" type="int" size='1' value='[3, 3]' /></attributelist></attribute><attribute name='learnrate' get='1' set='1' type='float64' size='1'>
        <digest>
          Learning Rate
        </digest>
        <description>
          <div class="document">
<p>The learning rate of the network. Start small, increase slowly.</p>
</div>

          <h5>Constraints</h5><ul><li>Minimum: 0.0</li><li>Maximum: 1.0</li></ul>
        </description><attributelist><attribute name="default" get="1" set="1" type="int" size='1' value='0.01' /></attributelist></attribute><attribute name='maxiter' get='1' set='1' type='int' size='1'>
        <digest>
          Maximum Number of Iterations
        </digest>
        <description>
          <div class="document">
<p>The maximum number of iterations to use in training.</p>
</div>

          <h5>Constraints</h5><ul><li>Minimum: 1</li></ul>
        </description><attributelist><attribute name="default" get="1" set="1" type="int" size='1' value='1000' /></attributelist></attribute><attribute name='momentum' get='1' set='1' type='float64' size='1'>
        <digest>
          Momentum
        </digest>
        <description>
          <div class="document">
<p>The training momentum, default 0.9</p>
</div>

          <h5>Constraints</h5><ul><li>Minimum: 0.0</li><li>Maximum: 0.99</li></ul>
        </description><attributelist><attribute name="default" get="1" set="1" type="int" size='1' value='0.9' /></attributelist></attribute><attribute name='outputactivation' get='1' set='1' type='int' size='1'>
        <digest>
          Output Activation Function
        </digest>
        <description>
          <div class="document">
<p>The activation function to use for the output layer units. Beware of the permitted ranges of each: relu (0-&gt;inf), sigmoid (0-&gt;1), tanh (-1,1)</p>
</div>

          
        </description><attributelist><attribute name="default" get="1" set="1" type="int" size='1' value='0' /></attributelist></attribute><attribute name='tapin' get='1' set='1' type='int' size='1'>
        <digest>
          Input Tap Index
        </digest>
        <description>
          <div class="document">
<p>The layer whose input is used to predict and predictPoint. It is 0 counting, where the default of 0 is the input layer, and 1 would be the first hidden layer, and so on.</p>
</div>

          <h5>Constraints</h5><ul><li>Minimum: 0</li></ul>
        </description><attributelist><attribute name="default" get="1" set="1" type="int" size='1' value='0' /></attributelist></attribute><attribute name='tapout' get='1' set='1' type='int' size='1'>
        <digest>
          Output Tap Index
        </digest>
        <description>
          <div class="document">
<p>The layer whose output to return. It is counting from 0 as the input layer, and 1 would be the first hidden layer, and so on. The default of -1 is the last layer of the whole network.</p>
</div>

          <h5>Constraints</h5><ul><li>Minimum: -1</li></ul>
        </description><attributelist><attribute name="default" get="1" set="1" type="int" size='1' value='-1' /></attributelist></attribute><attribute name='validation' get='1' set='1' type='float64' size='1'>
        <digest>
          Validation Amount
        </digest>
        <description>
          <div class="document">
<p>The fraction of the DataSet size to hold back during training to validate the network against.</p>
</div>

          <h5>Constraints</h5><ul><li>Minimum: 0</li><li>Maximum: 0.9</li></ul>
        </description><attributelist><attribute name="default" get="1" set="1" type="int" size='1' value='0.2' /></attributelist></attribute><attribute name='warnings' get='1' set='1' type='int' size='1'>
        <digest>
          Warnings
        </digest>
        <description>
          <div class="document">
<p>Enable warnings to be issued whenever a parameter value is constrained (e.g. clipped)</p>
</div>

          <h5>Constraints</h5><ul><li>Minimum: 0</li><li>Maximum: 1</li></ul>
        </description><attributelist><attribute name="default" get="1" set="1" type="int" size='1' value='0' /></attributelist></attribute></attributelist>
	<!--RELATED-->
	<seealsolist>
    
	</seealsolist>
</c74object>